\chapter{Introduction}

Determining the genetic sequence of a given organism is of interest to many, if not all, the biological sciences. \asq{Citar alguns artigos de diferentes áreas de biologia fazendo uso de informação genética?} Currently, however, it is not straightforward to translate a DNA molecule into the sequence of nucleic acids that constitute it. Sequencing technologies can, at best, produce subsequences of the original genome, known as sequencing reads, whose size varies according to the protocol used. When considering Whole Genome Sequencing (WGS), \tochange{read lengths are much smaller than even the shortest genome} \asq{Ended up being word-for-word as ref} \cite{Miller2010}. They need, therefore, to be put together to reconstruct the original sequence. The problem of assembling the reads into the genome has been proven to be \emph{NP-Hard} \cite{Medvedev2007}. As a result, optimizing the assembly process has been an ongoing effort in the field of bioinformatics, with Pevzner \emph{et al.} introducing the idea of breaking the read into even shorter sequences of length $k$, called \kmer{s}, and constructing a \dBG from them. A read can, then, be represented by a path on the resulting graph, and the assembly problem becomes that of finding an Eulerian path on the graph that includes all paths representing reads \cite{Pevzner2001}. Since then, the Eulerian superpath approach on the \dBG became standard in the construction of assemblers. Because the \dBG must be represented in memory, however, the space-efficiency of its representation can become a bottleneck for the assembly process, especially for larger genomes \cite{Chikhi2014}.

One important part of reducing memory usage of the \dBG is filtering the \kmer{s} found in the reads. This is needed because the reads are prone to containing sequencing errors that occur when, as an example, a base that is not found in the original sequence is erroneously inserted into the read, or a base that is present in the sequence is deleted or replaced \cite{Giani2020}. This requires that the reads be processed before they are used to construct the \dBG. One common step in this preprocessing phase is \kmer counting, where the number of times that each individual \kmer appears in the reads is tracked \cite{Zhang2014}. Due to how sequencing is performed, with any substring of the original genome being sequenced multiple times, real \kmer{s}, i.e. \kmer{s} found in the original sequence, are expected to have a high frequency in the reads, while spurious \kmer{s} are expected to appear only once or twice. This allows low-frequency \kmer{s} to be ignored when constructing the \dBG, including only those with a count close to the expected for real \kmer{s} \cite{Conway2011}\cite{Ghosh2019}.

\asq{falta uma cola aqui}

In this work, we will introduce a methodology for tackling both ends of improving the space-efficiency of \dBG. First we introduce a new represetation based on a \cm sketch \cite{Cormode2005} that can be constructed directly from the unprocessed reads, filtering out low-frequency \kmer{s}. By traversing this structure, we can further identify and filter spurious \kmer{s}. We show that, although the \cm{-based} representation introduces count errors, it is still successful in removing most (over $80\%$) of the spurious \kmer{s} from the reads. We also show that the remaining $20\%$ are further filtered out by traversal of the graph, leading to only a relatively small number of false \kmer{s} being represented in the graph, less than $2\%$ of the graph. This allows us to insert almost exclusively high-quality \kmer{s} into a novel probabilistic hashtable-based representation of a \dBG. We then show that this new data structure introduces some new false \kmer{s}, but they never exceeded $16\%$ of the \kmer{s} represented in the graph.