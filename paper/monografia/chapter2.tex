\chapter{Theoretical Foundation and Related Work}

\changed{In this chapter we begin by setting the theoretical groundwork for understanding \dBG{s} in the context of genome assembly. We then discuss some related work on \kmer counting as well as succinct representations of the \dBG.}

\section{Notation}

\changed{Throughout this work, we use lower-case symbols, such as $t$ and $c$, to represent scalar values. Uppercase symbols, such as $\strname{X}$ and $\strname{Y}$, represent strings. Finally, calligraphic uppercase symbols, such as $\readset$ and $\strsetname{S}$, are used to represent sets. Strings and sets are $0$-indexed, and the notation $X[i:j]$ represents the substring of $X$ from position $i$ up to, but not including, position $j$. The concatenation of two strings $X$ and $Y$, or a string $X$ and a character $a$, are respectively denoted by $X\cdot Y$ and $X\cdot a$.}

\section{\dBG{s}}
\label{sec:dBG}

% - Detailed explanation of \dBG of a set of DNA sequences
%   - reverse complements
% - How it is going to be used
% - Operations
%   - Insert node
%   - Insert edge
%   - Query node
%   - Query edge / star 
% - Space-efficient representations - that's what we propose

The \keyterm{\dBG of order $k$} of a string \strdef{x}{n}, $G(X;k)=(V,E)$, is defined as the directed graph whose nodes $V$ represent all distinct \kmer{s} (i.e. substrings of length $k$) of \strname{X}, and such that any two nodes representing $(k-1)$-overlapping \kmer{s} are connected by an edge labeled by the last character of the second \kmer. For example if $k=3$ and $X$ contains the substring \chr{ACGT} then the consecutive triplets \chr{ACG} and \chr{CGT} will originate the edge $\chr{ACG}\stackrel{\chr{C}}{\longrightarrow}\chr{CGT}$. Hence the edges $E$ represent all distinct $(k+1)$-mers of $X$. 
% That is, given two nodes on the graph, they each represent a distinct sequence of symbols $S_1$ and $S_2$, and there is an edge between them if and only if the tail of $S_1$ is the head of $S_2$.

In genome sequencing, \dB graphs are used in the assembly process to represent the distinct \kmer{s} in a set \readset of randomly distributed fragments of the source DNA \strname{S}, called \keyterm{reads}, generated by the sequencing machines. The amount and total length of the reads is determined by the \keyterm{coverage} of the sequencing process, i.e. the number of times \strname{S} was cloned and sequenced. Ideally, \strname{S} could be obtained from an Eulerian traversal of $G(\readset, k)$. Unfortunately however, due to sequencing errors and repeats, such a straightforward approach is not feasible, but the \dBG can still be used to produce a collection of partial assemblies, called \keyterm{contigs}, which can then be further combined to form the original genome \cite{Pevzner2001}. Figure~\ref{fig:dbgexample} presents an example of the \dBG in this context.

\begin{figure}[htbp]
	\begin{center}
    \includegraphics[width=0.8\textwidth]{figures/dbg-example}
	\end{center}
	\caption{Example of a \dBG. $k=4$}\label{fig:dbgexample}
\end{figure}

\section{Reverse Complements}
\label{subsec:dBG-reversecomplements}

One difficulty of using \dBG{s} to represent DNA data is the presence of \keyterm{reverse complements}. When generating sequencing reads, the machine reads either of the two complementary strands of a fragment of the input DNA. That is, the output read may correspond to the sequence \strname{S} in the forward (5'-3') direction, or its reverse complement \strname{\overline{S}} in the backward (3'-5') direction, with
\strname{\overline{S}} being obtained from \strname{S} by swapping each base with its Watson-Crick complement
($\A \leftrightarrow \T$, $\C \leftrightarrow \G$) and then reversing the string, and vice versa. For example, the reverse complement of the sequence $S=\chr{AGTACGGTC}$ is $\overline{S}=\chr{GACCGTACT}$ and vice versa.

To deal with reverse complements, reads are processed twice, once in each direction. Nodes representing \kmer{s} that are reverse complements of each other are merged, with edges made bidirectional. Alternatively, those nodes can be kept distinct, resulting in a symmetric graph in which, as noted by Conway \& Bromage, ``a forward traversal corresponds to the backwards traversal on the reverse complement path, and vice versa.'' \cite{Conway2011}
% As in \cite{Conway2011}, this will be treated by processing
% all reads in both directions, without, however, merging nodes representing reverse complements. As noted by Conway \& Bromage: ``This
% makes the graph symmetric; a forward traversal corresponds to a backwards traversal on the reverse complement path, and vice versa.``
% \cite{Conway2011}

\section{Selecting the \kmer{s} for the \dBG}
\label{subsec:dBG-selectingkmers}

Another difficulty of using a \dBG to represent DNA data is dealing with sequencing errors. During the sequencing process, there is a small error rate associated with reading any base from \strname{S} (0.1\%--1\% per base in Illumina \cite{Metzker2010}). As a result, many of the \kmer{s} extracted from the reads in \readset are erroneous. As discussed by Conway \& Bromage, this causes the number of spurious \kmer{s} to grow proportionally to the number of bases in the reads $|\readset|=\sum_{\strname{X}_i \in \readset} |\strname{X}_i|$, determined by the coverage, while the number of true \kmer{s} is proportional to the size of the genome $|\strname{S}|$ \cite{Conway2011}.

Although modern sequencing machines generate a quality score associated with each base, it is not possible to know exactly what parts of the reads are erroneous, and so we cannot tell whether a \kmer should be added to the \dBG without more information. However, real \kmer{s} are expected to appear a number of times close to the sequencing coverage $c$, or a multiple of $c$ in case of repeats, whereas spurious \kmer{s} resulting from sequencing errors are commonly low-frequency or even unique \cite{Conway2011, Zhang2014, Ghosh2019}. Therefore, a natural way of filtering the \kmer{s} obtained from the reads is to discard those that have a low frequency. Hence we consider a \kmer to be a real \kmer \emph{iff} it occurs more than some threshold $t$, in which case we add it to the \dBG.

\section{Counting \kmers}

\changed{Counting \kmer{s} in a set of reads in a time- and space-efficient manner is a challenging task, commonly performed as a preprocessing step to the \dBG construction \cite{Zhang2014}, and for which many different approaches have been proposed. 

Mar√ßais \& Kingsford introduced \emph{Jellyfish} in 2001, a hashtable-based approach for \kmer counting that controls memory usage by identifying when the hashtable will grow beyond the available memory, in which case its contents are written to disk and the table cleared. It can, then, merge the partial hashtables saved in disk storage \cite{Marcais2011}.

\emph{BFCounter}, introduced by Melsted \& Pritchard, also uses a hashtable to track \kmer counts, but it uses a Bloom Filter (BF) to skip unique \kmer{s}. It does two passes over the sequencing reads, identifying the \kmer{s} that appear more than once by verifying if they were already introduced into a BF on the first pass, and then using a hashtable to count only the nonunique \kmer{s} on the second \cite{Melsted2011}.

Rizk \emph{et al.} later introduced \emph{DSK}, which makes use of disk storage to track \kmer counts thus saving main memory. The tool allows for controlling how much disk storage is used by sacrificing some processing time. It separates the \kmer{s} from the reads into a set of files whose number and size is determined by the target memory and disk usage given as an input. The \kmer{s} in each file are then counted using a hashtable \cite{Rizk2013}.

Similar to \emph{BFCounter}, \emph{Turtle} uses a BF to track \kmer{s} appearing at least twice, adding \kmer occurrences to fixed-length array. Once the array is filled, it is sorted such that occurrences of the same \kmer appear next to each other. These occurrences can then be merged into a single array entry containing the number of times that \kmer occurred, freeing memory for the process to continue. For cases where the number of frequent \kmer{s} is too large to fit into the array, they also introduce a probabilistic approach using counting BF's \cite{Roy2014}.

Zhang \emph{et al.} use a \cm sketch (discussed in Section~\ref{sec:countmin}) as a probabilistic approach to \kmer counting that incurs in some miscount rate. They show that this rate can be controlled by increasing the memory requirements of the sketch. They also show that, despite the miscount rate, the abundance profiles generated by \emph{khmer} could be used for measuring sequencing error profiles and for performing read trimming \cite{Zhang2014}.

It is also possible to introduce \kmer counting directly as a part of the \dBG construction. \emph{FastEtch} is an assembler which uses a small \cm sketch to allow for the online construction of the \dBG by filtering spurious \kmer{s} based on abundance. As \kmer{s} are taken from the reads, they are used to update counters on the \cm sketch. Once a threshold is reached, the \kmer is added to a hashtable-based exact representation of the \dBG. Because the authors use a small \cm sketch, many collisions are expected to occur and many false positives are expected to go through. They propose two methods for reducing these occurrences which are based on keeping track of how many \kmer{s} have been added to the \dBG due the count of any individual bucket of the \cm. Once a bucket has caused too many \kmer{s} to be inserted into the graph, it is reset. They present two variations of an assembler that offer a good time-memory-quality tradeoff \cite{Ghosh2019}.}

\section{\dBG representation}
\label{subsec:dBG-representation}

A \dBG can be represented either by its set of nodes (\kmer{s}) or edges ($(k+1)$-mers) equivalently, as one can be derived from the other. Therefore, a structure that can determine if a given node $x$ is a member of $G$ can represent the \dBG. Conway \& Bromage showed that the lower bound on the space required to \emph{exactly} represent these \keyterm{membership data structures} (MDS's) is $\Omega(n \log n)$, with $n=|V(G)|$ \cite{Conway2011}. \changed{They achieve a succinct representation of the graph by storing its edges in a compressed bitmap, allowing the graph to be represented using approximately 28~bits per edge \cite{Conway2011}.}

In order to further improve space-efficiency, new representations were created that trade deterministic exactness for a probabilistic approach. Pell \emph{et al.} showed that a probabilistic representation based on a BF could accuratly represent a \dBG with as little as 4~bits per \kmer \changed{while keeping false positive rates at $15\%$ or lower} \cite{Pell2012}.

However, Bowe \emph{et al.} \cite{Bowe2012} and Chikhi \& Rizk \cite{Chikhi2013} independently observed that giving up deterministic exactness isn't the only option for obtaining better space-efficiency, introducing two new representations that use $O(n)$ and $O(n \log k)$ bits, respectively, and allow for an exact traversal of the \dBG from a starting set of known member nodes. This is possible due to the fact that a \dBG is not queried for membership of random nodes, but rather for potential neighbors of nodes already known to be in the graph. As such, the structures designed by the two groups do not offer a deterministically exact membership query operation, instead offering a neighborhood query operation that is exact for the members of the graph \cite{Bowe2012, Chikhi2013}. Chikhi \emph{et al.} later named this new form of representation a \keyterm{Navigational Data Structure} (NDS) and showed that the lower bound on the number of bits required to exactly represent a \dBG with an NDS is $3.24n$ \cite{Chikhi2014}.

\changed{Chikhi \& Rizk's implementation follows Pell \emph{et al.}'s approach \cite{Pell2012} by using a BF to store the nodes in the graph. However, they use a separate standard set to exactly store only the false positive neighbors of true \kmer{s}, which they call \emph{cFP} for critical false positives, such that a \kmer is considered to be represented in the graph iff it is considered present in the BF, but not in the \emph{cFP} set. This allows them to construct an exact representation of the \dBG in $13.2$~bits per \kmer \cite{Chikhi2013}.

Salikhov \emph{et al.} expanded on the work of Chikhi \& Rizk by storing the \emph{cFP}'s in a BF. Because this can incur in some true positives being considered false positives, they use a second BF to store these `false false positives'. They show that, in theory, they could achieve a representation of the \dBG using $8.45$~bits per \kmer using an infinite set of BF's. In practice, however, they use a finite set of filters, with a set of \emph{cFP}'s that are not resolved by those filters. They show that using just two filters is enough to resolve $95\%$ of queries without using the set, and four filters resolve over $99\%$ of queries. This allows them to improve on the results by Chikhi \& Rizk \cite{Chikhi2013} by constructing a representation that needs only between $8.5$ and $9$~bits per \kmer \cite{Salikhov2014}.}

\changed{In the same paper where they establish the lower bound on space-efficiency for NDS's, Chikhi \emph{et al.} introduced \emph{DBGFM}, which represents the \dBG not as the set of \kmer{s} individually, but through the set of maximal simple paths on the graph. A naive approach for storing the set of paths would provide an extremelly succint representation, but at the cost of query time. The authors, however, achieve a good tradeoff between the two resources by using an FM-index to speed up queries. The resulting structure can still represent a \dBG in as few as $3.53$~bits per \kmer. To avoid using a larger intermediate representation of the \dBG to perform the construction of the maximal simple paths (called compaction) on, the authors introduce a new algorithm, \emph{BCALM}, to produce the maximal simple paths using low-memory. This incurs in an upfront time cost for the compaction of the \dBG. Furthermore, this compaction is achieved in low-memory by making use of disk storage \cite{Chikhi2014}.}

Beyond the distinction between probabilistic and exact, and MDSs and NDSs, there is also a distinction between \keyterm{static} and \keyterm{dynamic} representations for \dBG. Static representations are constructed once and never altered, whereas dynamic representations support operations such as insertion and deletion of nodes, useful in population-scale studies due to their everchanging nature \cite{Alipanahi2021}. \changed{Such structures fall beyond the scope of this work, however.}

% A \dBG can be represented either by its set of nodes (\kmers) or edges ($(k+1)$-mers) equivalently, as one can be derived from the other.
% As such, a structure that can answer queries about the presence of a given node on the graph is enough to
% represent the graph. Conway\&Bromage showed that the lower bound on the space required to
% \emph{exactly} represent a \dBG is $\Omega(n \log n)$ bits, where $n$ is the number of nodes\remove[isn't this obvious?]{,
% and $4^k > n$}\cite{Conway2011}.

% \asq{Isso precisa ser reescrito: NDSs n√£o s√£o necessariamente representa√ß√µes probabilisticas. Elas apenas substituem a consulta de presen√ßa de um n√≥ pela consulta de vizinhan√ßa.}

% In order to further improve space-efficiency, new representations were created that trade deterministic exactness for a probabilistic approach. For instance, the so-called \keyterm{Navigational Data Structures} (NDS) have some probability of giving an erroneous answer to a membership query, 
% but can still be used to navigate the graph \cite{Chikhi2014}. This \change{definition is useful}{is} due to the fact that a \dBG is usually not queried for membership of \change{randomly selected}{random} nodes, but rather \remove{only} potential neighbors of \change{a known member node is queried}{nodes already known to be in the graph}. In the same paper where they introduce
% the idea of NDS \cite{Chikhi2014}\paguso{correct?}\asq{Esse artigo de Chikhi \emph{et al.} √© a introdu√ß√£o e formaliza√ß√£o do conceito de NDSs em oposi√ß√£o √†s Membership Data Structures. Em segunda leitura, por√©m, categorizar nossas estruturas como NDSs √© incorreto porque NDSs devem dar respostas exatas para consultas de vizinhan√ßa, o que n√≥s n√£o garantimos.}, Chikhi \emph{et al.} also present a lower bound for the number of bits needed to represent such a structure as $3.24n$.
% In sections \ref{sec:debruijncountmin} and \ref{sec:debruijnhashtable} we will introduce two new NDS's. \asq{√â necess√°rio reiterar
% os objetivos das duas estrutas aqui, visto que isso j√° seria feito na introdu√ß√£o e √© feito nas pr√≥prias sess√µes dedicadas a cada estrutura?}\paguso{at√© o momento, acho que n√£o.}

\section{\dBG operations}
\label{subsubsec:dbg-operations}

Chikhi \emph{et al.} \cite{Chikhi2019} present the following set of operations common to many data structures for representing a \dBG.

\begin{enumerate}
  \item \emph{Construction} of the data structure
  \item \emph{Insertion} of a new \kmer
  \item \emph{Deletion} of an existing \kmer.
  \item \emph{Membership query}: Given a \kmer $X$, returns true \emph{iff} $X \in G$
  \item \emph{Forward neighbor query}: Given a \kmer $X$ and a base $a$, returns true \emph{iff} $X[1:k] \cdot a \in G$
  \item \emph{Backward neighbor query}: Given a \kmer $X$ and a base $a$, return true \emph{iff} $a \cdot X[0:k-1] \in G$.
\end{enumerate}

Note that a representation that implements the \emph{construction} and \emph{membeship query} operation can use those to implement some version of the others (e.g. by reconstructing the graph with the desired insertion or deletion, or by querying for the membership of the desired neighbor). However, dynamic representations implement \emph{insertion} and \emph{deletion} operations that do not require the reconstruction of the graph, while NDSs don't rely on the membership query to establish if a given forward or backward neighbor is represented in the graph. For example, the neighborhood query described by Chikhi \emph{et al.} \cite{Chikhi2014} as defining NDSs can be implemented by performing \emph{forward} and \emph{backward neighbor queries} for all extensions of the given \kmer and then returning only those for which the result was $\mathit{true}$.