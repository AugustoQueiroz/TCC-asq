\chapter{Conclusion}

We conclude this work by summarizing our main findings, and presenting a brief list of topics for further development.

\section{Main results and contributions}

The experimental analysis described in Chapter~\ref{chap:results} allows us to conclude the following.

\paragraph*{\cm{-based} \kmer counting can be used to filter spurious \kmer{s} from sequencing reads}

We start by noticing that our \dBCM variation of the \cm sketch can be used to filter spurious \kmers resulting from sequencing errors.
We expand on the results presented by Zhang \emph{et al.} \cite{Zhang2014} to show that, despite overcounting, we can still filter out most (over $80\%$) of spurious \kmer{s} based on the count estimate from a \cm sketch that has fewer cells than the number of distinct \kmer{s} in the reads, and uses only $16$ bits per cell. These results are similar to what \emph{khmer} achieves through iteratively truncating the reads at the first low-frequency \kmer \cite{Zhang2014}, i.e. \emph{read trimming}. However, filtering directly from the counts only requires that the reads be processed once.

\paragraph*{Filtering through traversal is very effective}

We have also shown that traversing the \dBG generated from the high-frequency \kmer{s} further improves filtering of spurious \kmer{s} without affecting the number of real \kmer{s} represented. Therefore, although Ghosh \& Kalyanaraman \cite{Ghosh2019} present a framework for using the \cm sketch for online filtering of spurious \kmer{s} that allows the sketch to be considerably smaller, reducing the size of the \cm sketch much further than presented here hinders its ability to be successfully navigated, losing a very efficient second filter that removed nearly $98\%$ of the remaining spurious \kmer{s} after count-based filtering. This would decrease memory requirement during processing of the reads, but results in a less succinct final representation of the \dBG.

\paragraph*{Storing outedges improves traversal}

We also see that, for both data structures used, the number of outedges stored for each node in the \dBG is low, with the vast majority having only one recorded outedge. Without using the outedges, and querying all four possible neighbors of a given node, we would need to query between two to four times as many \kmer{s}, just from the nodes represented in the \dBG. Storing the outedges, even with some chance of false positives, can therefore decrease the impact of the false positive rate associated with the membership query of either structure by preventing false \kmer{s} from even being queried. Moreover, by reducing the number of queries, storing the set of outedges also improves time performance of traversals or related operations.

\paragraph*{The \dBHT can succesfully represent a \dBG in as few as $9$ bits per \kmer}

Finally, we have shown that the \dBHT can represent a \dBG in as few as $9$ bits per \kmer with, at most, $16\%$ of the graph being composed of false \kmer{s} introduced by the probabilistic nature of the representation. Based on the exploration by Pell \emph{et al.} \cite{Pell2012}, we expect this number of false positives not to affect usability of the graph for assembly. We can reduce it, however, by increasing the size of the \dBHT. With $16$ bits per \kmer, we achieved a number of false positive nodes that is below $4\%$ of the total number of \kmer{s} represented in the graph. Moreover, our final \dBHT representation is very efficient, with node and edge queries performed in constant time through a few simple operations.
These results are comparable to current \dBG representations, that span from $4$ bits per \kmer to $24$ bits per \kmer \cite{Chikhi2013, Giani2020}.

\section{Future Work}

Although we have satisfactorily achieved the main goals proposed for this work, we have identified a few points that would benefit from further work. 

\paragraph*{Comparing our methods to similar work}

It would be important to compare the results obtained in this project to related work more directly. In particular, we would like to show that the \cm{-based} filter used in \emph{FastEtch} is less effective in filtering spurious \kmer{s} than the pipeline we introduce, based on count and traversal. We would also like to show that despite providing a slightly less succinct \dBG representation in the form of a \dBHT, this structure has better performance than Bloom Filter-based representations\paguso{citar alguma referência}, due to reducing the number of potential neighbor queries, and the number of hashing functions to only one in practice\paguso{the fingerprint is obtained from the fibhash}.

\paragraph*{Generating contigs and N50 score for the \dBHT}

A natural next step is to use the \dBHT to generate maximal contigs and, from them, compute the \keyterm{N50 score}, defined as the length $l_0$ of the shortest contig such that all contigs with length $l \geq l_0$ cover at least $50\%$ of the assembled sequences. The N50 score is used to determine the quality of an assembly in terms of contiguity. Based on the distribution of outedges observed during traversal of the \dBHT, we expect this representation to perform fairly well.

%\paragraph*{Use the \dBHT as visited set during traversal of \dBCM}
\paragraph*{Optimizing parts of the implementation}

We have implemented the methods described herein in C-language for maximum performance. However, a few things can still be streamlined and optimized.
For instance, we have used a queue and a set to store respectively the nodes to be visited and the ones already visited during the \dBCM traversal. In practice, this approach is not interesting as it ultimately requires representing the \dBG in memory as a set, in parallel to the succinct representation being constructed, which is prohibitive for larger genomes. It would be interesting to see how using the \dBHT itself, as it is being constructed, as the set of visited nodes would affect its final result. Because of false positives, this could result in true nodes not being visited, and therefore not represented in the graph. \paguso{você não vai querer uma discussão muito longa sobre o que não está tão bem.}

\medskip

All the findings outlined above suggest that our approach is a viable alternative and offers interesting tradeoffs for the representation of \dBG{s} for genomic data, with challenging and promising opportunities for further development.
