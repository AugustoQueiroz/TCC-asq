@article{Cormode2005,
   abstract = {We introduce a new sublinear space data structure - the count-min sketch - for summarizing data streams. Our sketch allows fundamental queries in data stream summarization such as point, range, and inner product queries to be approximately answered very quickly; in addition, it can be applied to solve several important problems in data streams such as finding quantiles, frequent items, etc. The time and space bounds we show for using the CM sketch to solve these problems significantly improve those previously known - typically from 1/ε2 to 1/ε in factor. © 2003 Elsevier Inc. All rights reserved.},
   author = {Graham Cormode and S. Muthukrishnan},
   doi = {10.1016/j.jalgor.2003.12.001},
   issn = {01966774},
   issue = {1},
   journal = {Journal of Algorithms},
   month = {4},
   pages = {58-75},
   title = {An improved data stream summary: The count-min sketch and its applications},
   volume = {55},
   year = {2005},
}

@article{Conway2011,
   abstract = {Motivation: Second-generation sequencing technology makes it feasible for many researches to obtain enough sequence reads to attempt the de novo assembly of higher eukaryotes (including mammals). De novo assembly not only provides a tool for understanding wide scale biological variation, but within human biomedicine, it offers a direct way of observing both large-scale structural variation and fine-scale sequence variation. Unfortunately, improvements in the computational feasibility for de novo assembly have not matched the improvements in the gathering of sequence data. This is for two reasons: the inherent computational complexity of the problem and the in-practice memory requirements of tools. Results: In this article, we use entropy compressed or succinct data structures to create a practical representation of the de Bruijn assembly graph, which requires at least a factor of 10 less storage than the kinds of structures used by deployed methods. Moreover, because our representation is entropy compressed, in the presence of sequencing errors it has better scaling behaviour asymptotically than conventional approaches. We present results of a proof-of-concept assembly of a human genome performed on a modest commodity server. © The Author 2011. Published by Oxford University Press. All rights reserved.},
   author = {Thomas C. Conway and Andrew J. Bromage},
   doi = {10.1093/bioinformatics/btq697},
   issn = {13674803},
   issue = {4},
   journal = {Bioinformatics},
   month = {2},
   pages = {479-486},
   pmid = {21245053},
   title = {Succinct data structures for assembling large genomes},
   volume = {27},
   year = {2011},
}

@article{Chikhi2014,
   abstract = {The de Bruijn graph plays an important role in bioinformatics, especially in the context of de novo assembly. However, the representation of the de Bruijn graph in memory is a computational bottleneck for many assemblers. Recent papers proposed a navigational data structure approach in order to improve memory usage. We prove several theoretical space lower bounds to show the limitation of these types of approaches. We further design and implement a general data structure (DBGFM) and demonstrate its use on a human whole-genome dataset, achieving space usage of 1.5 GB and a 46% improvement over previous approaches. As part of DBGFM, we develop the notion of frequency-based minimizers and show how it can be used to enumerate all maximal simple paths of the de Bruijn graph using only 43 MB of memory. Finally, we demonstrate that our approach can be integrated into an existing assembler by modifying the ABySS software to use DBGFM.},
   author = {Rayan Chikhi and Antoine Limasset and Shaun Jackman and Jared Simpson and Paul Medvedev},
   month = {1},
   title = {On the representation of de Bruijn graphs},
   url = {http://arxiv.org/abs/1401.5383},
   year = {2014},
}

@article{Leinonen2011,
   abstract = {The combination of significantly lower cost and increased speed of sequencing has resulted in an explosive growth of data submitted into the primary next-generation sequence data archive, the Sequence Read Archive (SRA). The preservation of experimental data is an important part of the scientific record, and increasing numbers of journals and funding agencies require that next-generation sequence data are deposited into the SRA. The SRA was established as a public repository for the next-generation sequence data and is operated by the International Nucleotide Sequence Database Collaboration (INSDC). INSDC partners include the National Center for Biotechnology Information (NCBI), the European Bioinformatics Institute (EBI) and the DNA Data Bank of Japan (DDBJ). The SRA is accessible at http://www.ncbi.nlm.nih.gov/Traces/sra from NCBI, at http://www.ebi.ac.uk/ena from EBI and at http://trace.ddbj.nig.ac.jp from DDBJ. In this article, we present the content and structure of the SRA, detail our support for sequencing platforms and provide recommended data submission levels and formats. We also briefly outline our response to the challenge of data growth.},
   author = {Rasko Leinonen and Hideaki Sugawara and Martin Shumway and International Nucleotide Sequence Database Collaboration},
   doi = {10.1093/nar/gkq1019},
   edition = {2010/11/09},
   issn = {1362-4962},
   issue = {Database issue},
   journal = {Nucleic acids research},
   keywords = {*Databases, Nucleic Acid,*High-Throughput Nucleotide Sequencing},
   month = {1},
   pages = {D19-D21},
   pmid = {21062823},
   publisher = {Oxford University Press},
   title = {The sequence read archive},
   volume = {39},
   url = {https://pubmed.ncbi.nlm.nih.gov/21062823 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3013647/},
   year = {2011},
}

@article{Ghosh2019,
   abstract = {De novo genome assembly describes the process of reconstructing an unknown genome from a large collection of short or long reads sequenced from the genome. A single run of a Next-Generation Sequencing NGS technology can produce billions of short reads, making genome assembly computationally demanding both in terms of memory and time. One of the major computational steps in modern day short read assemblers involves the construction and use of a string data structure called the de Bruijn graph. In fact, a majority of short read assemblers build the complete de Bruijn graph for the set of input reads, and subsequently traverse and prune low-quality edges, in order to generate genomic "contigs"-the output of assembly. These steps of graph construction and traversal, contribute to well over 90 percent of the runtime and memory. In this paper, we present a fast algorithm, FastEtch, that uses sketching to build an approximate version of the de Bruijn graph for the purpose of generating an assembly. The algorithm uses Count-Min sketch, which is a probabilistic data structure for streaming data sets. The result is an approximate de Bruijn graph that stores information pertaining only to a selected subset of nodes that are most likely to contribute to the contig generation step. In addition, edges are not stored; instead that fraction which contribute to our contig generation are detected on-the-fly. This approximate approach is intended to significantly improve performance both execution time and memory footprint whilst possibly compromising on the output assembly quality. We present two main versions of the assembler-one that generates an assembly, where each contig represents a contiguous genomic region from one strand of the DNA, and another that generates an assembly, where the contigs can straddle either of the two strands of the DNA. For further scalability, we have implemented a multi-threaded parallel code. Experimental results using our algorithm conducted on E. coli, Yeast, C. elegans, and Human Chr2 and Chr2+3 genomes show that our method yields one of the best time-memory-quality trade-offs, when compared against many state-of-the-art genome assemblers.},
   author = {Priyanka Ghosh and Ananth Kalyanaraman},
   doi = {10.1109/TCBB.2017.2737999},
   issn = {15579964},
   issue = {4},
   journal = {IEEE/ACM Transactions on Computational Biology and Bioinformatics},
   keywords = {Approximation methods,Count-min sketch,De Bruijn graph,Genome assembly},
   month = {7},
   pages = {1091-1106},
   pmid = {28910776},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {FastEtch: A fast sketch-based assembler for genomes},
   volume = {16},
   year = {2019},
}

@article{Zhang2014,
   abstract = {K-mer abundance analysis is widely used for many purposes in nucleotide sequence analysis, including data preprocessing for de novo assembly, repeat detection, and sequencing coverage estimation. We present the khmer software package for fast and memory efficient online counting of k-mers in sequencing data sets. Unlike previous methods based on data structures such as hash tables, suffix arrays, and trie structures, khmer relies entirely on a simple probabilistic data structure, a Count-Min Sketch. The Count-Min Sketch permits online updating and retrieval of k-mer counts in memory which is necessary to support online k-mer analysis algorithms. On sparse data sets this data structure is considerably more memory efficient than any exact data structure. In exchange, the use of a Count-Min Sketch introduces a systematic overcount for kmers; moreover, only the counts, and not the k-mers, are stored. Here we analyze the speed, the memory usage, and the miscount rate of khmer for generating k-mer frequency distributions and retrieving k-mer counts for individual k-mers. We also compare the performance of khmer to several other k-mer counting packages, including Tallymer, Jellyfish, BFCounter, DSK, KMC, Turtle and KAnalyze. Finally, we examine the effectiveness of profiling sequencing error, k-mer abundance trimming, and digital normalization of reads in the context of high khmer false positive rates. khmer is implemented in C++ wrapped in a Python interface, offers a tested and robust API, and is freely available under the BSD license at github.com/ged-lab/khmer. © 2014 Zhang et al.},
   author = {Qingpeng Zhang and Jason Pell and Rosangela Canino-Koning and Adina Chuang Howe and C. Titus Brown},
   doi = {10.1371/journal.pone.0101271},
   issn = {19326203},
   issue = {7},
   journal = {PLoS ONE},
   month = {7},
   pmid = {25062443},
   publisher = {Public Library of Science},
   title = {These are not the K-mers you are looking for: Efficient online K-mer counting using a probabilistic data structure},
   volume = {9},
   year = {2014},
}
