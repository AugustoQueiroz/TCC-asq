@article{Cormode2005,
   abstract = {We introduce a new sublinear space data structure - the count-min sketch - for summarizing data streams. Our sketch allows fundamental queries in data stream summarization such as point, range, and inner product queries to be approximately answered very quickly; in addition, it can be applied to solve several important problems in data streams such as finding quantiles, frequent items, etc. The time and space bounds we show for using the CM sketch to solve these problems significantly improve those previously known - typically from 1/ε2 to 1/ε in factor. © 2003 Elsevier Inc. All rights reserved.},
   author = {Graham Cormode and S. Muthukrishnan},
   doi = {10.1016/j.jalgor.2003.12.001},
   issn = {01966774},
   issue = {1},
   journal = {Journal of Algorithms},
   month = {4},
   pages = {58-75},
   title = {An improved data stream summary: The count-min sketch and its applications},
   volume = {55},
   year = {2005},
}

@article{Conway2011,
   abstract = {Motivation: Second-generation sequencing technology makes it feasible for many researches to obtain enough sequence reads to attempt the de novo assembly of higher eukaryotes (including mammals). De novo assembly not only provides a tool for understanding wide scale biological variation, but within human biomedicine, it offers a direct way of observing both large-scale structural variation and fine-scale sequence variation. Unfortunately, improvements in the computational feasibility for de novo assembly have not matched the improvements in the gathering of sequence data. This is for two reasons: the inherent computational complexity of the problem and the in-practice memory requirements of tools. Results: In this article, we use entropy compressed or succinct data structures to create a practical representation of the de Bruijn assembly graph, which requires at least a factor of 10 less storage than the kinds of structures used by deployed methods. Moreover, because our representation is entropy compressed, in the presence of sequencing errors it has better scaling behaviour asymptotically than conventional approaches. We present results of a proof-of-concept assembly of a human genome performed on a modest commodity server. © The Author 2011. Published by Oxford University Press. All rights reserved.},
   author = {Thomas C. Conway and Andrew J. Bromage},
   doi = {10.1093/bioinformatics/btq697},
   issn = {13674803},
   issue = {4},
   journal = {Bioinformatics},
   month = {2},
   pages = {479-486},
   pmid = {21245053},
   title = {Succinct data structures for assembling large genomes},
   volume = {27},
   year = {2011},
}

@article{Chikhi2014,
   abstract = {The de Bruijn graph plays an important role in bioinformatics, especially in the context of de novo assembly. However, the representation of the de Bruijn graph in memory is a computational bottleneck for many assemblers. Recent papers proposed a navigational data structure approach in order to improve memory usage. We prove several theoretical space lower bounds to show the limitation of these types of approaches. We further design and implement a general data structure (DBGFM) and demonstrate its use on a human whole-genome dataset, achieving space usage of 1.5 GB and a 46% improvement over previous approaches. As part of DBGFM, we develop the notion of frequency-based minimizers and show how it can be used to enumerate all maximal simple paths of the de Bruijn graph using only 43 MB of memory. Finally, we demonstrate that our approach can be integrated into an existing assembler by modifying the ABySS software to use DBGFM.},
   author = {Rayan Chikhi and Antoine Limasset and Shaun Jackman and Jared Simpson and Paul Medvedev},
   month = {1},
   title = {On the representation of de Bruijn graphs},
   url = {http://arxiv.org/abs/1401.5383},
   year = {2014},
}

@article{Leinonen2011,
   abstract = {The combination of significantly lower cost and increased speed of sequencing has resulted in an explosive growth of data submitted into the primary next-generation sequence data archive, the Sequence Read Archive (SRA). The preservation of experimental data is an important part of the scientific record, and increasing numbers of journals and funding agencies require that next-generation sequence data are deposited into the SRA. The SRA was established as a public repository for the next-generation sequence data and is operated by the International Nucleotide Sequence Database Collaboration (INSDC). INSDC partners include the National Center for Biotechnology Information (NCBI), the European Bioinformatics Institute (EBI) and the DNA Data Bank of Japan (DDBJ). The SRA is accessible at http://www.ncbi.nlm.nih.gov/Traces/sra from NCBI, at http://www.ebi.ac.uk/ena from EBI and at http://trace.ddbj.nig.ac.jp from DDBJ. In this article, we present the content and structure of the SRA, detail our support for sequencing platforms and provide recommended data submission levels and formats. We also briefly outline our response to the challenge of data growth.},
   author = {Rasko Leinonen and Hideaki Sugawara and Martin Shumway and International Nucleotide Sequence Database Collaboration},
   doi = {10.1093/nar/gkq1019},
   edition = {2010/11/09},
   issn = {1362-4962},
   issue = {Database issue},
   journal = {Nucleic acids research},
   keywords = {*Databases, Nucleic Acid,*High-Throughput Nucleotide Sequencing},
   month = {1},
   pages = {D19-D21},
   pmid = {21062823},
   publisher = {Oxford University Press},
   title = {The sequence read archive},
   volume = {39},
   url = {https://pubmed.ncbi.nlm.nih.gov/21062823 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3013647/},
   year = {2011},
}

@article{Ghosh2019,
   abstract = {De novo genome assembly describes the process of reconstructing an unknown genome from a large collection of short or long reads sequenced from the genome. A single run of a Next-Generation Sequencing NGS technology can produce billions of short reads, making genome assembly computationally demanding both in terms of memory and time. One of the major computational steps in modern day short read assemblers involves the construction and use of a string data structure called the de Bruijn graph. In fact, a majority of short read assemblers build the complete de Bruijn graph for the set of input reads, and subsequently traverse and prune low-quality edges, in order to generate genomic "contigs"-the output of assembly. These steps of graph construction and traversal, contribute to well over 90 percent of the runtime and memory. In this paper, we present a fast algorithm, FastEtch, that uses sketching to build an approximate version of the de Bruijn graph for the purpose of generating an assembly. The algorithm uses Count-Min sketch, which is a probabilistic data structure for streaming data sets. The result is an approximate de Bruijn graph that stores information pertaining only to a selected subset of nodes that are most likely to contribute to the contig generation step. In addition, edges are not stored; instead that fraction which contribute to our contig generation are detected on-the-fly. This approximate approach is intended to significantly improve performance both execution time and memory footprint whilst possibly compromising on the output assembly quality. We present two main versions of the assembler-one that generates an assembly, where each contig represents a contiguous genomic region from one strand of the DNA, and another that generates an assembly, where the contigs can straddle either of the two strands of the DNA. For further scalability, we have implemented a multi-threaded parallel code. Experimental results using our algorithm conducted on E. coli, Yeast, C. elegans, and Human Chr2 and Chr2+3 genomes show that our method yields one of the best time-memory-quality trade-offs, when compared against many state-of-the-art genome assemblers.},
   author = {Priyanka Ghosh and Ananth Kalyanaraman},
   doi = {10.1109/TCBB.2017.2737999},
   issn = {15579964},
   issue = {4},
   journal = {IEEE/ACM Transactions on Computational Biology and Bioinformatics},
   keywords = {Approximation methods,Count-min sketch,De Bruijn graph,Genome assembly},
   month = {7},
   pages = {1091-1106},
   pmid = {28910776},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {FastEtch: A fast sketch-based assembler for genomes},
   volume = {16},
   year = {2019},
}

@article{Zhang2014,
   abstract = {K-mer abundance analysis is widely used for many purposes in nucleotide sequence analysis, including data preprocessing for de novo assembly, repeat detection, and sequencing coverage estimation. We present the khmer software package for fast and memory efficient online counting of k-mers in sequencing data sets. Unlike previous methods based on data structures such as hash tables, suffix arrays, and trie structures, khmer relies entirely on a simple probabilistic data structure, a Count-Min Sketch. The Count-Min Sketch permits online updating and retrieval of k-mer counts in memory which is necessary to support online k-mer analysis algorithms. On sparse data sets this data structure is considerably more memory efficient than any exact data structure. In exchange, the use of a Count-Min Sketch introduces a systematic overcount for kmers; moreover, only the counts, and not the k-mers, are stored. Here we analyze the speed, the memory usage, and the miscount rate of khmer for generating k-mer frequency distributions and retrieving k-mer counts for individual k-mers. We also compare the performance of khmer to several other k-mer counting packages, including Tallymer, Jellyfish, BFCounter, DSK, KMC, Turtle and KAnalyze. Finally, we examine the effectiveness of profiling sequencing error, k-mer abundance trimming, and digital normalization of reads in the context of high khmer false positive rates. khmer is implemented in C++ wrapped in a Python interface, offers a tested and robust API, and is freely available under the BSD license at github.com/ged-lab/khmer. © 2014 Zhang et al.},
   author = {Qingpeng Zhang and Jason Pell and Rosangela Canino-Koning and Adina Chuang Howe and C. Titus Brown},
   doi = {10.1371/journal.pone.0101271},
   issn = {19326203},
   issue = {7},
   journal = {PLoS ONE},
   month = {7},
   pmid = {25062443},
   publisher = {Public Library of Science},
   title = {These are not the K-mers you are looking for: Efficient online K-mer counting using a probabilistic data structure},
   volume = {9},
   year = {2014},
}

@article{Pevzner2001,
doi = {10.1073/pnas.171285098},
author = {Pavel A. Pevzner  and Haixu Tang  and Michael S. Waterman },
title = {An Eulerian path approach to DNA fragment assembly},
journal = {Proceedings of the National Academy of Sciences},
volume = {98},
number = {17},
pages = {9748-9753},
year = {2001},
doi = {10.1073/pnas.171285098},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.171285098},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.171285098},
abstract = {For the last 20 years, fragment assembly in DNA sequencing
 followed the “overlap–layout–consensus” paradigm that is used
 in all currently available assembly tools. Although this approach
 proved useful in assembling clones, it faces difficulties in genomic
 shotgun assembly. We abandon the classical
 “overlap–layout–consensus” approach in favor of a new
 euler algorithm that, for the first time, resolves the
 20-year-old “repeat problem” in fragment assembly. Our main
 result is the reduction of the fragment assembly to a variation of the
 classical Eulerian path problem that allows one to generate accurate
 solutions of large-scale sequencing problems. euler, in
 contrast to the celera assembler, does not mask such
 repeats but uses them instead as a powerful fragment assembly tool.}
}

@article{Pell2012,
   abstract = {Deep sequencing has enabled the investigation of a wide range of environmental microbial ecosystems, but the high memory requirements for de novo assembly of short-read shotgun sequencing data from these complex populations are an increasingly large practical barrier. Here we introduce a memory-efficient graph representation with which we can analyze the k-mer connectivity of metagenomic samples. The graph representation is based on a probabilistic data structure, a Bloom filter, that allows us to efficiently store assembly graphs in as little as 4 bits per k-mer, albeit inexactly. We show that this data structure accurately represents DNA assembly graphs in low memory. We apply this data structure to the problem of partitioning assembly graphs into components as a prelude to assembly, and show that this reduces the overall memory requirements for de novo assembly of metagenomes. On one soil metagenome assembly, this approach achieves a nearly 40-fold decrease in the maximum memory requirements for assembly. This probabilistic graph representation is a significant theoretical advance in storing assembly graphs and also yields immediate leverage on metagenomic assembly.},
   author = {Jason Pell and Arend Hintze and Rosangela Canino-Koning and Adina Howe and James M Tiedje and C Titus Brown},
   doi = {10.1073/pnas.1121464109},
   issue = {33},
   journal = {Proceedings of the National Academy of Sciences},
   pages = {13272-13277},
   title = {Scaling metagenome sequence assembly with probabilistic de Bruijn graphs},
   volume = {109},
   url = {https://www.pnas.org/doi/abs/10.1073/pnas.1121464109},
   year = {2012},
}

@report{Chikhi2013,
   abstract = {Background: The de Bruijn graph data structure is widely used in next-generation sequencing (NGS). Many programs, e.g. de novo assemblers, rely on in-memory representation of this graph. However, current techniques for representing the de Bruijn graph of a human genome require a large amount of memory (≥ 30 GB). Results: We propose a new encoding of the de Bruijn graph, which occupies an order of magnitude less space than current representations. The encoding is based on a Bloom filter, with an additional structure to remove critical false positives. Conclusions: An assembly software implementing this structure, Minia, performed a complete de novo assembly of human genome short reads using 5.7 GB of memory in 23 hours.},
   author = {Rayan Chikhi and Guillaume Rizk},
   journal = {Algorithms for Molecular Biology},
   keywords = {Bloom filter,de Bruijn graph,de novo assembly},
   pages = {22},
   title = {Space-efficient and exact de Bruijn graph representation based on a Bloom filter},
   volume = {8},
   url = {http://www.almob.org/content/8/1/22},
   year = {2013},
}

@inproceedings{Bowe2012,
  title={Succinct de Bruijn graphs},
  author={Bowe, Alexander and Onodera, Taku and Sadakane, Kunihiko and Shibuya, Tetsuo},
  booktitle={International workshop on algorithms in bioinformatics},
  pages={225--235},
  year={2012},
  organization={Springer}
}

@article{Chikhi2019,
  author = {Chikhi, Rayan and Holub, Jan and Medvedev, Paul},
  title = {Data Structures to Represent a Set of k-Long DNA Sequences},
  year = {2021},
  issue_date = {January 2022},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {54},
  number = {1},
  issn = {0360-0300},
  url = {https://doi.org/10.1145/3445967},
  doi = {10.1145/3445967},
  abstract = {The analysis of biological sequencing data has been one of the biggest applications of string algorithms. The approaches used in many such applications are based on the analysis of k-mers, which are short fixed-length strings present in a dataset. While these approaches are rather diverse, storing and querying a k-mer set has emerged as a shared underlying component. A set of k-mers has unique features and applications that, over the past 10 years, have resulted in many specialized approaches for its representation. In this survey, we give a unified presentation and comparison of the data structures that have been proposed to store and query a k-mer set. We hope this survey will serve as a resource for researchers in the field as well as make the area more accessible to researchers outside the field.},
  journal = {ACM Comput. Surv.},
  month = {mar},
  articleno = {17},
  numpages = {22},
  keywords = {Bloom filters, unitgs, data structures, k-mers, FM-index, navigational data structures, de Bruijn graphs, biological sequencing data, k-mer sets}
}

@generic{Metzker2010,
   abstract = {Demand has never been greater for revolutionary technologies that deliver fast, inexpensive and accurate genome information. This challenge has catalysed the development of next-generation sequencing (NGS) technologies. The inexpensive production of large volumes of sequence data is the primary advantage over conventional methods. Here, I present a technical review of template preparation, sequencing and imaging, genome alignment and assembly approaches, and recent advances in current and near-term commercially available NGS instruments. I also outline the broad range of applications for NGS technologies, in addition to providing guidelines for platform selection to address biological questions of interest. © 2010 Macmillan Publishers Limited. All rights reserved.},
   author = {Michael L. Metzker},
   doi = {10.1038/nrg2626},
   issn = {14710056},
   issue = {1},
   journal = {Nature Reviews Genetics},
   month = {1},
   pages = {31-46},
   pmid = {19997069},
   title = {Sequencing technologies the next generation},
   volume = {11},
   year = {2010},
}

@article{Alipanahi2021,
    author = {Alipanahi, Bahar and Kuhnle, Alan and Puglisi, Simon J and Salmela, Leena and Boucher, Christina},
    title = "{Succinct dynamic de Bruijn graphs}",
    journal = {Bioinformatics},
    volume = {37},
    number = {14},
    pages = {1946-1952},
    year = {2021},
    month = {07},
    abstract = "{The de Bruijn graph is one of the fundamental data structures for analysis of high throughput sequencing data. In order to be applicable to population-scale studies, it is essential to build and store the graph in a space- and time-efficient manner. In addition, due to the ever-changing nature of population studies, it has become essential to update the graph after construction, e.g. add and remove nodes and edges. Although there has been substantial effort on making the construction and storage of the graph efficient, there is a limited amount of work in building the graph in an efficient and mutable manner. Hence, most space efficient data structures require complete reconstruction of the graph in order to add or remove edges or nodes.In this article, we present DynamicBOSS, a succinct representation of the de Bruijn graph that allows for an unlimited number of additions and deletions of nodes and edges. We compare our method with other competing methods and demonstrate that DynamicBOSS is the only method that supports both addition and deletion and is applicable to very large samples (e.g. greater than 15 billion k-mers). Competing dynamic methods, e.g. FDBG cannot be constructed on large scale datasets, or cannot support both addition and deletion, e.g. BiFrost. DynamicBOSS is publicly available at https://github.com/baharpan/dynboss.Supplementary data are available at Bioinformatics online. }",
    issn = {1367-4803},
    doi = {10.1093/bioinformatics/btaa546},
    url = {https://doi.org/10.1093/bioinformatics/btaa546},
    eprint = {https://academic.oup.com/bioinformatics/article-pdf/37/14/1946/39569364/btaa546.pdf},
}

@article{Huang2011,
    author = {Huang, Weichun and Li, Leping and Myers, Jason R. and Marth, Gabor T.},
    title = "{ART: a next-generation sequencing read simulator}",
    journal = {Bioinformatics},
    volume = {28},
    number = {4},
    pages = {593-594},
    year = {2011},
    month = {12},
    abstract = "{Summary: ART is a set of simulation tools that generate synthetic next-generation sequencing reads. This functionality is essential for testing and benchmarking tools for next-generation sequencing data analysis including read alignment, de novo assembly and genetic variation discovery. ART generates simulated sequencing reads by emulating the sequencing process with built-in, technology-specific read error models and base quality value profiles parameterized empirically in large sequencing datasets. We currently support all three major commercial next-generation sequencing platforms: Roche's 454, Illumina's Solexa and Applied Biosystems' SOLiD. ART also allows the flexibility to use customized read error model parameters and quality profiles.Availability: Both source and binary software packages are available at http://www.niehs.nih.gov/research/resources/software/artContact:weichun.huang@nih.gov; gabor.marth@bc.eduSupplementary information:Supplementary data are available at Bioinformatics online.}",
    issn = {1367-4803},
    doi = {10.1093/bioinformatics/btr708},
    url = {https://doi.org/10.1093/bioinformatics/btr708},
    eprint = {https://academic.oup.com/bioinformatics/article-pdf/28/4/593/16911715/btr708.pdf},
}

@misc{Skarupke2018,
  author = {Malte Skarupke},
  title = {Fibonacci Hashing: The Optimization that the World Forgot (or: a Better Alternative to Integer Modulo)},
  year = 2018,
  howpublished = {\url{https://probablydance.com/2018/06/16/fibonacci-hashing-the-optimization-that-the-world-forgot-or-a-better-alternative-to-integer-modulo/amp/}},
  note = {Accessed: 2022-05-08}
}

@misc{ecoligenome,
   howpublished = {\url{http://ftp.ensemblgenomes.org/pub/bacteria/release-52/fasta/bacteria_0_collection/escherichia_coli_str_k_12_substr_mg1655_gca_000005845/dna/}},
   note = {Accessed: 2022-05-12}
}

@generic{Imelfort2009,
   abstract = {The ability to sequence the DNA of an organism has become one of the most important tools in modern biological research. Until recently, the sequencing of even small model genomes required substantial funds and international collaboration. The development of 'second-generation' sequencing technology has increased the throughput and reduced the cost of sequence generation by several orders of magnitude. These new methods produce vast numbers of relatively short reads, usually at the expense of read accuracy. Since the first commercial second-generation sequencing system was produced by 454 Technologies and commercialised by Roche, several other companies including Illumina, Applied Biosystems, Helicos Biosciences and Pacific Biosciences have joined the competition. Because of the relatively high error rate and lack of assembly tools, short-read sequence technology has mainly been applied to the re-sequencing of genomes. However, some recent applications have focused on the de novo assembly of these data. De novo assembly remains the greatest challenge for DNA sequencing and there are specific problems for second generation sequencing which produces short reads with a high error rate. However, a number of different approaches for short-read assembly have been proposed and some have been implemented in working software. In this review, we compare the current approaches for second-generation genome sequencing, explore the future direction of this technology and the implications for plant genome research. © The Author 2009. Published by Oxford University Press.},
   author = {Michael Imelfort and David Edwards},
   doi = {10.1093/bib/bbp039},
   issn = {14675463},
   issue = {6},
   journal = {Briefings in Bioinformatics},
   keywords = {De novo assembly,Genome sequencing,Illumina,Next generation,Roche 454,Second generation},
   pages = {609-618},
   pmid = {19933209},
   title = {De novo sequencing of plant genomes using second-generation technologies},
   volume = {10},
   year = {2009},
}

@inproceedings{Medvedev2007,
   author = {Medvedev, Paul and Georgiou, Konstantinos and Myers, Gene and Brudno, Michael},
   title = {Computability of Models for Sequence Assembly},
   year = {2007},
   isbn = {3540741259},
   publisher = {Springer-Verlag},
   address = {Berlin, Heidelberg},
   abstract = {Graph-theoretic models have come to the forefront as some of the most powerful and practical methods for sequence assembly. Simultaneously, the computational hardness of the underlying graph algorithms has remained open. Here we present two theoretical results about the complexity of these models for sequence assembly. In the first part, we show sequence assembly to be NP-hard under two different models: string graphs and de Bruijn graphs. Together with an earlier result on the NP-hardness of overlap graphs, this demonstrates that all of the popular graph-theoretic sequence assembly paradigms are NP-hard. In our second result, we give the first, to our knowledge, optimal polynomial time algorithm for genome assembly that explicitly models the double-strandedness of DNA. We solve the Chinese Postman Problem on bidirected graphs using bidirected flow techniques and show to how to use it to find the shortest doublestranded DNA sequence which contains a given set of k-long words. This algorithm has applications to sequencing by hybridization and short read assembly.},
   booktitle = {Proceedings of the 7th International Conference on Algorithms in Bioinformatics},
   pages = {289–301},
   numpages = {13},
   location = {Philadelphia, PA},
   series = {WABI'07}
}

@article{Giani2020,
   title = {Long walk to genomics: History and current approaches to genome sequencing and assembly},
   journal = {Computational and Structural Biotechnology Journal},
   volume = {18},
   pages = {9-19},
   year = {2020},
   issn = {2001-0370},
   doi = {https://doi.org/10.1016/j.csbj.2019.11.002},
   url = {https://www.sciencedirect.com/science/article/pii/S2001037019303277},
   author = {Alice Maria Giani and Guido Roberto Gallo and Luca Gianfranceschi and Giulio Formenti},
   keywords = {Genome assembly, Sequencing, Reference, Bioinformatics, Next-generation, Third-generation},
   abstract = {Genomes represent the starting point of genetic studies. Since the discovery of DNA structure, scientists have devoted great efforts to determine their sequence in an exact way. In this review we provide a comprehensive historical background of the improvements in DNA sequencing technologies that have accompanied the major milestones in genome sequencing and assembly, ranging from early sequencing methods to Next-Generation Sequencing platforms. We then focus on the advantages and challenges of the current technologies and approaches, collectively known as Third Generation Sequencing. As these technical advancements have been accompanied by progress in analytical methods, we also review the bioinformatic tools currently employed in de novo genome assembly, as well as some applications of Third Generation Sequencing technologies and high-quality reference genomes.}
}

@generic{Miller2010,
   abstract = {The emergence of next-generation sequencing platforms led to resurgence of research in whole-genome shotgun assembly algorithms and software. DNA sequencing data from the Roche 454, Illumina/Solexa, and ABI SOLiD platforms typically present shorter read lengths, higher coverage, and different error profiles compared with Sanger sequencing data. Since 2005, several assembly software packages have been created or revised specifically for de novo assembly of next-generation sequencing data. This review summarizes and compares the published descriptions of packages named SSAKE, SHARCGS, VCAKE, Newbler, Celera Assembler, Euler, Velvet, ABySS, AllPaths, and SOAPdenovo. More generally, it compares the two standard methods known as the de Bruijn graph approach and the overlap/layout/consensus approach to assembly. © 2010 Elsevier Inc.},
   author = {Jason R. Miller and Sergey Koren and Granger Sutton},
   doi = {10.1016/j.ygeno.2010.03.001},
   issn = {08887543},
   issue = {6},
   journal = {Genomics},
   keywords = {Genome assembly algorithms,Next-generation sequencing},
   month = {6},
   pages = {315-327},
   pmid = {20211242},
   title = {Assembly algorithms for next-generation sequencing data},
   volume = {95},
   year = {2010},
}

@article{Brinda2021,
   abstract = {de Bruijn graphs play an essential role in bioinformatics, yet they lack a universal scalable representation. Here, we introduce simplitigs as a compact, efficient, and scalable representation, and ProphAsm, a fast algorithm for their computation. For the example of assemblies of model organisms and two bacterial pan-genomes, we compare simplitigs to unitigs, the best existing representation, and demonstrate that simplitigs provide a substantial improvement in the cumulative sequence length and their number. When combined with the commonly used Burrows-Wheeler Transform index, simplitigs reduce memory, and index loading and query times, as demonstrated with large-scale examples of GenBank bacterial pan-genomes.},
   author = {Karel Břinda and Michael Baym and Gregory Kucherov},
   doi = {10.1186/s13059-021-02297-z},
   issn = {1474-760X},
   issue = {1},
   journal = {Genome Biology},
   pages = {96},
   title = {Simplitigs as an efficient and scalable representation of de Bruijn graphs},
   volume = {22},
   url = {https://doi.org/10.1186/s13059-021-02297-z},
   year = {2021},
}

@article{Gallant1980,
   title = {On finding minimal length superstrings},
   journal = {Journal of Computer and System Sciences},
   volume = {20},
   number = {1},
   pages = {50-58},
   year = {1980},
   issn = {0022-0000},
   doi = {https://doi.org/10.1016/0022-0000(80)90004-5},
   url = {https://www.sciencedirect.com/science/article/pii/0022000080900045},
   author = {John Gallant and David Maier and James Astorer},
   abstract = {A superstring of a set of strings {s1,…, sn} is a string s containing each si, 1 ⩽ i ⩽ n, as a substring. The superstring problem is: Given a set S of strings and a positive integer K, does S have a superstring of length K? The superstring problem has applications to data storage; specifically, data compression. We consider the complexity of the superstring problem. NP-completeness results dealing with sets of strings over both finite and infinite alphabets are presented. Also, for a restricted version of the superstring problem, a linear time algorithm is given.}
}

@generic{Shendure2008,
   abstract = {DNA sequence represents a single format onto which a broad range of biological phenomena can be projected for high-throughput data collection. Over the past three years, massively parallel DNA sequencing platforms have become widely available, reducing the cost of DNA sequencing by over two orders of magnitude, and democratizing the field by putting the sequencing capacity of a major genome center in the hands of individual investigators. These new technologies are rapidly evolving, and near-term challenges include the development of robust protocols for generating sequencing libraries, building effective new approaches to data-analysis, and often a rethinking of experimental design. Next-generation DNA sequencing has the potential to dramatically accelerate biological and biomedical research, by enabling the comprehensive analysis of genomes, transcriptomes and interactomes to become inexpensive, routine and widespread, rather than requiring significant production-scale efforts. © 2008 Nature Publishing Group.},
   author = {Jay Shendure and Hanlee Ji},
   doi = {10.1038/nbt1486},
   issn = {10870156},
   issue = {10},
   journal = {Nature Biotechnology},
   month = {10},
   pages = {1135-1145},
   pmid = {18846087},
   title = {Next-generation DNA sequencing},
   volume = {26},
   year = {2008},
}

@article{Melsted2011,
   abstract = {Background: Counting k-mers (substrings of length k in DNA sequence data) is an essential component of many methods in bioinformatics, including for genome and transcriptome assembly, for metagenomic sequencing, and for error correction of sequence reads. Although simple in principle, counting k-mers in large modern sequence data sets can easily overwhelm the memory capacity of standard computers. In current data sets, a large fraction-often more than 50%-of the storage capacity may be spent on storing k-mers that contain sequencing errors and which are typically observed only a single time in the data. These singleton k-mers are uninformative for many algorithms without some kind of error correction.Results: We present a new method that identifies all the k-mers that occur more than once in a DNA sequence data set. Our method does this using a Bloom filter, a probabilistic data structure that stores all the observed k-mers implicitly in memory with greatly reduced memory requirements. We then make a second sweep through the data to provide exact counts of all nonunique k-mers. For example data sets, we report up to 50% savings in memory usage compared to current software, with modest costs in computational speed. This approach may reduce memory requirements for any algorithm that starts by counting k-mers in sequence data with errors.Conclusions: A reference implementation for this methodology, BFCounter, is written in C++ and is GPL licensed. It is available for free download at http://pritch.bsd.uchicago.edu/bfcounter.html. © 2011 Melsted and Pritchard; licensee BioMed Central Ltd.},
   author = {Páll Melsted and Jonathan K. Pritchard},
   doi = {10.1186/1471-2105-12-333},
   issn = {14712105},
   journal = {BMC Bioinformatics},
   month = {8},
   pmid = {21831268},
   title = {Efficient counting of k-mers in DNA sequences using a bloom filter},
   volume = {12},
   year = {2011},
}

@article{10.1093/bioinformatics/bty500,
    author = {Crawford, Victoria G and Kuhnle, Alan and Boucher, Christina and Chikhi, Rayan and Gagie, Travis},
    title = "{Practical dynamic de Bruijn graphs}",
    journal = {Bioinformatics},
    volume = {34},
    number = {24},
    pages = {4189-4195},
    year = {2018},
    month = {06},
    abstract = "{The de Bruijn graph is fundamental to the analysis of next generation sequencing data and so, as datasets of DNA reads grow rapidly, it becomes more important to represent de Bruijn graphs compactly while still supporting fast assembly. Previous implementations of compact de Bruijn graphs have not supported node or edge deletion, however, which is important for pruning spurious elements from the graph.Belazzougui et al. (2016b) recently proposed a compact and fully dynamic representation, which supports exact membership queries and insertions and deletions of both nodes and edges. In this paper, we give a practical implementation of their data structure, supporting exact membership queries and fully dynamic edge operations, as well as limited support for dynamic node operations. We demonstrate experimentally that its performance is comparable to that of state-of-the-art implementations based on Bloom filters.Our source-code is publicly available at https://github.com/csirac/dynamicDBG under an open-source license.}",
    issn = {1367-4803},
    doi = {10.1093/bioinformatics/bty500},
    url = {https://doi.org/10.1093/bioinformatics/bty500},
    eprint = {https://academic.oup.com/bioinformatics/article-pdf/34/24/4189/27088776/bty500.pdf},
}

@report{Salikhov2014,
   abstract = {Background: De Brujin graphs are widely used in bioinformatics for processing next-generation sequencing data. Due to a very large size of NGS datasets, it is essential to represent de Bruijn graphs compactly, and several approaches to this problem have been proposed recently. Results: In this work, we show how to reduce the memory required by the data structure of Chikhi and Rizk (WABI'12) that represents de Brujin graphs using Bloom filters. Our method requires 30% to 40% less memory with respect to their method, with insignificant impact on construction time. At the same time, our experiments showed a better query time compared to the method of Chikhi and Rizk. Conclusion: The proposed data structure constitutes, to our knowledge, currently the most efficient practical representation of de Bruijn graphs.},
   author = {Kamil Salikhov and Gustavo Sacomoto and Gregory Kucherov},
   issue = {2},
   journal = {Algorithms for Molecular Biology},
   keywords = {Bloom filter,Genome assembly,Next-generation sequencing,de Brujin graph},
   title = {Using cascading Bloom filters to improve the memory usage for de Brujin graphs},
   volume = {9},
   url = {http://www.almob.org/content/9/1/2},
   year = {2014},
}

@article{Lohmann2014,
   abstract = {The introduction of next generation sequencing (NGS) has led to an exponential increase of elucidated genetic causes in both extremely rare diseases and common but heterogeneous disorders. It can be applied to the whole or to selected parts of the genome (genome or exome sequencing, gene panels). NGS is not only useful in large extended families with linkage information, but may also be applied to detect de novo mutations or mosaicism in sporadic patients without a prior hypothesis about the mutated gene. Currently, NGS is applied in both research and clinical settings, and there is a rapid transition of research findings to diagnostic applications. These developments may greatly help to minimize the “diagnostic odyssey” for patients as whole-genome analysis can be performed in a few days at reasonable costs compared with gene-by-gene analysis based on Sanger sequencing following diverse clinical tests. Despite the enthusiasm about NGS, one has to keep in mind its limitations, such as a coverage and accuracy of < 100 %, resulting in missing variants and false positive findings. In addition, variant interpretation is challenging as there is usually more than one candidate variant found. Therefore, there is an urgent need to define standards for NGS with respect to run quality and variant interpretation, as well as mechanisms of quality control. Further, there are ethical challenges including incidental findings and how to guide unaffected probands seeking direct-to-customer testing. However, taken together, the application of NGS in research and diagnostics provides a tremendous opportunity to better serve our patients.},
   author = {Katja Lohmann and Christine Klein},
   doi = {10.1007/s13311-014-0288-8},
   issn = {1878-7479},
   issue = {4},
   journal = {Neurotherapeutics},
   pages = {699-707},
   title = {Next Generation Sequencing and the Future of Genetic Diagnosis},
   volume = {11},
   url = {https://doi.org/10.1007/s13311-014-0288-8},
   year = {2014},
}

@article{Kapun2013,
   abstract = {De Bruijn Superwalk with Multiplicities Problem is the problem of finding a walk in the de Bruijn graph containing several walks as subwalks and passing through each edge the exactly predefined number of times (equal to the multiplicity of this edge). This problem has been stated in the talk by Paul Medvedev and Michael Brudno on the first RECOMB Satellite Conference on Open Problems in Algorithmic Biology in August 2012. In this paper we show that this problem is NP-hard. Combined with results of previous works it means that all known models for genome assembly are NP-hard.},
   author = {Evgeny Kapun and Fedor Tsarev},
   doi = {10.1186/1471-2105-14-S5-S7},
   issn = {1471-2105},
   issue = {5},
   journal = {BMC Bioinformatics},
   pages = {S7},
   title = {De Bruijn Superwalk with Multiplicities Problem is NP-hard},
   volume = {14},
   url = {https://doi.org/10.1186/1471-2105-14-S5-S7},
   year = {2013},
}

@article{Marcais2011,
    author = {Marçais, Guillaume and Kingsford, Carl},
    title = "{A fast, lock-free approach for efficient parallel counting of occurrences of k-mers}",
    journal = {Bioinformatics},
    volume = {27},
    number = {6},
    pages = {764-770},
    year = {2011},
    month = {01},
    abstract = "{Motivation: Counting the number of occurrences of every k-mer (substring of length k) in a long string is a central subproblem in many applications, including genome assembly, error correction of sequencing reads, fast multiple sequence alignment and repeat detection. Recently, the deep sequence coverage generated by next-generation sequencing technologies has caused the amount of sequence to be processed during a genome project to grow rapidly, and has rendered current k-mer counting tools too slow and memory intensive. At the same time, large multicore computers have become commonplace in research facilities allowing for a new parallel computational paradigm.Results: We propose a new k-mer counting algorithm and associated implementation, called Jellyfish, which is fast and memory efficient. It is based on a multithreaded, lock-free hash table optimized for counting k-mers up to 31 bases in length. Due to their flexibility, suffix arrays have been the data structure of choice for solving many string problems. For the task of k-mer counting, important in many biological applications, Jellyfish offers a much faster and more memory-efficient solution.Availability: The Jellyfish software is written in C++ and is GPL licensed. It is available for download at http://www.cbcb.umd.edu/software/jellyfish.Contact:gmarcais@umd.eduSupplementary information:Supplementary data are available at Bioinformatics online.}",
    issn = {1367-4803},
    doi = {10.1093/bioinformatics/btr011},
    url = {https://doi.org/10.1093/bioinformatics/btr011},
    eprint = {https://academic.oup.com/bioinformatics/article-pdf/27/6/764/16902460/btr011.pdf},
}

@article{Rizk2013,
   abstract = {Counting all the k-mers (substrings of length k) in DNA/RNA sequencing reads is the preliminary step of many bioinformatics applications. However, state of the art k-mer counting methods require that a large data structure resides in memory. Such structure typically grows with the number of distinct k-mers to count. We present a new streaming algorithm for k-mer counting, called DSK (disk streaming of k-mers), which only requires a fixed, user-defined amount of memory and disk space. This approach realizes a memory, time and disk trade-off. The multi-set of all k-mers present in the reads is partitioned and partitions are saved to disk. Then, each partition is separately loaded in memory in a temporary hash table. The k-mer counts are returned by traversing each hash table. Low-abundance k-mers are optionally filtered. DSK is the first approach that is able to count all the 27-mers of a human genome dataset using only 4.0 GB of memory and moderate disk space (160 GB), in 17.9 hours. Availability: http://minia.genouest.org/dsk Contact: rayan.chikhi@ens-cachan.org},
   author = {Guillaume Rizk and Dominique Lavenier and Rayan Chikhi},
   doi = {10.1093/bioinfor},
   issue = {5},
   journal = {Bioinformatics},
   keywords = {()},
   pages = {652-653},
   publisher = {OUP},
   title = {DSK: k-mer counting with very low memory usage},
   year = {2013},
}

@article{Roy2014,
    author = {Roy, Rajat Shuvro and Bhattacharya, Debashish and Schliep, Alexander},
    title = "{ Turtle: Identifying frequent k -mers with cache-efficient algorithms }",
    journal = {Bioinformatics},
    volume = {30},
    number = {14},
    pages = {1950-1957},
    year = {2014},
    month = {03},
    abstract = "{Motivation: Counting the frequencies of k -mers in read libraries is often a first step in the analysis of high-throughput sequencing data. Infrequent k -mers are assumed to be a result of sequencing errors. The frequent k -mers constitute a reduced but error-free representation of the experiment, which can inform read error correction or serve as the input to de novo assembly methods. Ideally, the memory requirement for counting should be linear in the number of frequent k -mers and not in the, typically much larger, total number of k -mers in the read library. Results: We present a novel method that balances time, space and accuracy requirements to efficiently extract frequent k -mers even for high-coverage libraries and large genomes such as human. Our method is designed to minimize cache misses in a cache-efficient manner by using a pattern-blocked Bloom filter to remove infrequent k -mers from consideration in combination with a novel sort-and-compact scheme, instead of a hash, for the actual counting. Although this increases theoretical complexity, the savings in cache misses reduce the empirical running times. A variant of method can resort to a counting Bloom filter for even larger savings in memory at the expense of false-negative rates in addition to the false-positive rates common to all Bloom filter-based approaches. A comparison with the state-of-the-art shows reduced memory requirements and running times. Availability and implementation: The tools are freely available for download at http://bioinformatics.rutgers.edu/Software/Turtle and http://figshare.com/articles/Turtle/791582 . Contact:rajatroy@cs.rutgers.edu or schliep@cs.rutgers.eduSupplementary information:Supplementary data are available at Bioinformatics online. }",
    issn = {1367-4803},
    doi = {10.1093/bioinformatics/btu132},
    url = {https://doi.org/10.1093/bioinformatics/btu132},
    eprint = {https://academic.oup.com/bioinformatics/article-pdf/30/14/1950/17140212/btu132.pdf},
}

