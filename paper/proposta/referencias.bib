@inproceedings{Ghosh2016,
   abstract = {De novo genome assembly describes the process of reconstructing an unknown genome from a large collection of short (or long) reads sequenced from the genome. A single run of Next-Generation Sequencing (NGS) technologies can produce billions of reads, making genome assembly computationally demanding. One of the major computational steps in modern day short read assemblers involves the construction and use of a string data structure called the de Bruijn graph. In fact, a majority of short read assemblers build the complete de Bruijn graph for the set of input reads, and subsequently traverse and prune low-quality edges, in order to generate genomic "contigs" - the output of assembly. These steps of graph construction and traversal, contribute to well over 90% of the runtime and memory. In this paper, we present a fast algorithm, FastEtch, that uses sketching to build an approximate version of the de Bruijn graph for the purpose of generating an assembly. The algorithm uses Count-Min sketch, which is a probabilistic data structure for streaming data sets. The result is an approximate de Bruijn graph that stores information pertaining only to a selected subset of nodes that are most likely to contribute to the contig generation step. In addition, edges are not stored; instead that fraction which contribute to our contig generation are detected on-the-fly. This approximate approach is intended to significantly improve performance (both execution time and memory footprint) whilst possibly compromising on the output assembly quality. For further scalability, we have implemented a multi-threaded parallel code. Experimental results using our algorithm conducted on E. coli, Yeast, and C. elegans genomes show that our method is able to produce assemblies with quality comparable or better than most other state-of-the-art assemblers, while running in significantly reduced memory and time footprint.},
   author = {Priyanka Ghosh and Ananth Kalyanaraman},
   doi = {10.1145/2975167.2975192},
   isbn = {9781450342254},
   journal = {ACM-BCB 2016 - 7th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics},
   keywords = {Approximation methods,Count-Min sketch,De Bruijn graph,Genome assembly},
   month = {10},
   pages = {241-250},
   publisher = {Association for Computing Machinery, Inc},
   title = {A fast sketch-based assembler for genomes},
   year = {2016},
}

@report{Chikhi2013,
   abstract = {Background: The de Bruijn graph data structure is widely used in next-generation sequencing (NGS). Many programs, e.g. de novo assemblers, rely on in-memory representation of this graph. However, current techniques for representing the de Bruijn graph of a human genome require a large amount of memory (≥ 30 GB). Results: We propose a new encoding of the de Bruijn graph, which occupies an order of magnitude less space than current representations. The encoding is based on a Bloom filter, with an additional structure to remove critical false positives. Conclusions: An assembly software implementing this structure, Minia, performed a complete de novo assembly of human genome short reads using 5.7 GB of memory in 23 hours.},
   author = {Rayan Chikhi and Guillaume Rizk},
   journal = {Algorithms for Molecular Biology},
   keywords = {Bloom filter,de Bruijn graph,de novo assembly},
   pages = {22},
   title = {Space-efficient and exact de Bruijn graph representation based on a Bloom filter},
   volume = {8},
   url = {http://www.almob.org/content/8/1/22},
   year = {2013},
}

@article{Conway2011,
   abstract = {Motivation: Second-generation sequencing technology makes it feasible for many researches to obtain enough sequence reads to attempt the de novo assembly of higher eukaryotes (including mammals). De novo assembly not only provides a tool for understanding wide scale biological variation, but within human biomedicine, it offers a direct way of observing both large-scale structural variation and fine-scale sequence variation. Unfortunately, improvements in the computational feasibility for de novo assembly have not matched the improvements in the gathering of sequence data. This is for two reasons: the inherent computational complexity of the problem and the in-practice memory requirements of tools. Results: In this article, we use entropy compressed or succinct data structures to create a practical representation of the de Bruijn assembly graph, which requires at least a factor of 10 less storage than the kinds of structures used by deployed methods. Moreover, because our representation is entropy compressed, in the presence of sequencing errors it has better scaling behaviour asymptotically than conventional approaches. We present results of a proof-of-concept assembly of a human genome performed on a modest commodity server. © The Author 2011. Published by Oxford University Press. All rights reserved.},
   author = {Thomas C. Conway and Andrew J. Bromage},
   doi = {10.1093/bioinformatics/btq697},
   issn = {13674803},
   issue = {4},
   journal = {Bioinformatics},
   month = {2},
   pages = {479-486},
   pmid = {21245053},
   title = {Succinct data structures for assembling large genomes},
   volume = {27},
   year = {2011},
}
